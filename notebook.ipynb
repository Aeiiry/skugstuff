{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asyncio.log import logger\n",
    "import math\n",
    "from os import stat\n",
    "from random import choice\n",
    "import re\n",
    "from shutil import move\n",
    "import pandas\n",
    "import inspect\n",
    "import numpy\n",
    "import re as regex\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "date_strftime_format: str = \"%Y-%m-%y %H:%M:%S\"\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout,\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s %(message)s\",\n",
    "    datefmt=date_strftime_format,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-23 14:15:17 Combo input CSV:\n",
      "  Character                   Move Name  Expected Damage\n",
      "0     Annie  2LK 5MKx2 5HP 214P~P 236PP             4415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comboInputDf: pandas.DataFrame = pandas.read_csv(\"data/testcombo1.csv\")\n",
    "\n",
    "logger.debug(f\"Combo input CSV:\\n{comboInputDf}\\n\")\n",
    "\n",
    "character_reference_df: pandas.DataFrame = pandas.read_csv(\"data/characters.csv\")\n",
    "move_name_alias_df: pandas.DataFrame = pandas.read_csv(\"data/alias.csv\")\n",
    "full_framedata_df: pandas.DataFrame = pandas.read_csv(\"data/frameData.csv\")\n",
    "\n",
    "\n",
    "def create_df_copy_columns(df: pandas.DataFrame) -> pandas.DataFrame:\n",
    "    \"\"\"Creates a copy of a dataframe with the same columns\"\"\"\n",
    "    copy_df: pandas.DataFrame = pandas.DataFrame(columns=df.columns)\n",
    "    return copy_df\n",
    "\n",
    "\n",
    "def get_character_name() -> str:\n",
    "    return comboInputDf.iloc[0][\"Character\"]\n",
    "\n",
    "\n",
    "# get the expected damage for the combo, first value in the third column of the combo csv\n",
    "def get_expected_damage() -> int:\n",
    "    return comboInputDf.iloc[0][\"Expected Damage\"]\n",
    "\n",
    "\n",
    "expected_damage: int = get_expected_damage()\n",
    "\n",
    "# Set some constants\n",
    "character_name: str = get_character_name()\n",
    "move_column_name: str = \"Move Name\"\n",
    "\n",
    "# Set the character column in the comboDf to the character name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-23 14:15:17 Splitting Move Name on \" \"\n",
      "2023-02-23 14:15:17 Setting Character to Annie\n",
      "2023-02-23 14:15:17 Combo dataframe:\n",
      "  Character Move Name Alt Names Guard Properties Damage Meter On Hit On Block  \\\n",
      "0     Annie       2LK       NaN   NaN        NaN    NaN   NaN    NaN      NaN   \n",
      "1     Annie     5MKx2       NaN   NaN        NaN    NaN   NaN    NaN      NaN   \n",
      "2     Annie       5HP       NaN   NaN        NaN    NaN   NaN    NaN      NaN   \n",
      "3     Annie    214P~P       NaN   NaN        NaN    NaN   NaN    NaN      NaN   \n",
      "4     Annie     236PP       NaN   NaN        NaN    NaN   NaN    NaN      NaN   \n",
      "\n",
      "  Startup Active Recovery Hitstun Blockstun Hitstop On Pushblock Footer  \\\n",
      "0     NaN    NaN      NaN     NaN       NaN     NaN          NaN    NaN   \n",
      "1     NaN    NaN      NaN     NaN       NaN     NaN          NaN    NaN   \n",
      "2     NaN    NaN      NaN     NaN       NaN     NaN          NaN    NaN   \n",
      "3     NaN    NaN      NaN     NaN       NaN     NaN          NaN    NaN   \n",
      "4     NaN    NaN      NaN     NaN       NaN     NaN          NaN    NaN   \n",
      "\n",
      "  Thumbnail URL Footer URL  Expected Damage  \n",
      "0           NaN        NaN           4415.0  \n",
      "1           NaN        NaN           4415.0  \n",
      "2           NaN        NaN           4415.0  \n",
      "3           NaN        NaN           4415.0  \n",
      "4           NaN        NaN           4415.0  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def set_column_value(df: pandas.DataFrame, column: str, value: str) -> None:\n",
    "    logger.debug(f\"Setting {column} to {value}\")\n",
    "    df[column] = value\n",
    "\n",
    "\n",
    "# Create an empty dataframe to hold the combo data\n",
    "# Uses the same columns as tempFrameData\n",
    "combo_framedata_df: pandas.DataFrame = create_df_copy_columns(full_framedata_df)\n",
    "\n",
    "\n",
    "def split_columns(df: pandas.DataFrame, column_name, seperator) -> pandas.DataFrame:\n",
    "    splitdf = df.copy()\n",
    "    # split the values in a column on a given seperator\n",
    "    logger.debug(f'Splitting {column_name} on \"{seperator}\"')\n",
    "    splitdf[column_name] = splitdf[column_name].str.split(seperator)\n",
    "    # explode the column so that each value is on a row\n",
    "    splitdf: pandas.DataFrame = splitdf.explode(column_name)\n",
    "    return splitdf\n",
    "\n",
    "\n",
    "def concatenate_dataframes(df, inputdf) -> pandas.DataFrame:\n",
    "    # Concatenates two dataframes\n",
    "    return pandas.concat([df, inputdf], ignore_index=True)\n",
    "\n",
    "\n",
    "combo_framedata_df = concatenate_dataframes(\n",
    "    combo_framedata_df, split_columns(comboInputDf, move_column_name, \" \")\n",
    ")\n",
    "\n",
    "# Set the character column in the comboDf to the character name\n",
    "set_column_value(combo_framedata_df, \"Character\", character_name)\n",
    "\n",
    "\n",
    "logger.debug(f\"Combo dataframe:\\n{combo_framedata_df}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-23 14:15:17 Getting frame data for move [2LK]\n",
      "2023-02-23 14:15:17 Searching for [2LK] for character [Annie]\n",
      "2023-02-23 14:15:17 Move [2LK] found for character [Annie]\n",
      "2023-02-23 14:15:17 Move [2LK] is a repeat move\n",
      "2023-02-23 14:15:17 Searching for [2LK] for character [Annie]\n",
      "2023-02-23 14:15:17 Move [2LK] found for character [Annie]\n",
      "2023-02-23 14:15:17 Getting frame data for move [5MKx2]\n",
      "2023-02-23 14:15:17 Searching for [5MKx2] for character [Annie]\n",
      "2023-02-23 14:15:17 Move [5MKx2] not found, checking alternate names\n",
      "2023-02-23 14:15:17 Move [5MKx2] found for character [Annie]\n",
      "2023-02-23 14:15:17 Getting frame data for move [5HP]\n",
      "2023-02-23 14:15:17 Searching for [5HP] for character [Annie]\n",
      "2023-02-23 14:15:17 Move [5HP] found for character [Annie]\n",
      "2023-02-23 14:15:17 Move [5HP] is a repeat move\n",
      "2023-02-23 14:15:17 Searching for [5HP] for character [Annie]\n",
      "2023-02-23 14:15:17 Move [5HP] found for character [Annie]\n",
      "2023-02-23 14:15:17 Getting frame data for move [214P~P]\n",
      "2023-02-23 14:15:17 Searching for [214P~P] for character [Annie]\n",
      "2023-02-23 14:15:17 Move [214P~P] not found, checking alternate names\n",
      "2023-02-23 14:15:17 Move [214P~P] not found for character [Annie]\n",
      "2023-02-23 14:15:17 Move [214P~P] is a repeat move\n",
      "2023-02-23 14:15:17 Searching for [214P~P] for character [Annie]\n",
      "2023-02-23 14:15:17 Move [214P~P] not found, checking alternate names\n",
      "2023-02-23 14:15:17 Move [214P~P] not found for character [Annie]\n",
      "2023-02-23 14:15:17 Move name not found, checking aliases\n",
      "2023-02-23 14:15:17 Move 214P~P not found\n",
      "2023-02-23 14:15:17 Getting frame data for move [236PP]\n",
      "2023-02-23 14:15:17 Searching for [236PP] for character [Annie]\n",
      "2023-02-23 14:15:17 Move [236PP] not found, checking alternate names\n",
      "2023-02-23 14:15:17 Move [236PP] not found for character [Annie]\n",
      "2023-02-23 14:15:17 Move [236PP] is a repeat move\n",
      "2023-02-23 14:15:17 Searching for [236PP] for character [Annie]\n",
      "2023-02-23 14:15:17 Move [236PP] not found, checking alternate names\n",
      "2023-02-23 14:15:17 Move [236PP] not found for character [Annie]\n",
      "2023-02-23 14:15:17 Move name not found, checking aliases\n",
      "2023-02-23 14:15:17 Alias for [236PP] found as [MACRO_236PP]\n",
      "2023-02-23 14:15:17 Searching for [MACRO_236PP] for character [Annie]\n",
      "2023-02-23 14:15:17 Move [MACRO_236PP] not found, checking alternate names\n",
      "2023-02-23 14:15:17 Move [MACRO_236PP] found for character [Annie]\n"
     ]
    }
   ],
   "source": [
    "def find_move_from_name_and_character(\n",
    "    move_name: str, character_name: str, df\n",
    ") -> pandas.DataFrame:\n",
    "    \"\"\"Find a move from the move name and character name\n",
    "\n",
    "    Args:\n",
    "        move_name (str): The name of the move\n",
    "        character_name (str): The name of the character\n",
    "        df (pandas.DataFrame): The dataframe containing the move data\n",
    "    Returns:\n",
    "        pandas.DataFrame: The dataframe containing the move data\n",
    "    \"\"\"\n",
    "\n",
    "    logger.debug(f\"Searching for [{move_name}] for character [{character_name}]\")\n",
    "\n",
    "    alt_names_regex: str = (\n",
    "        rf\"^{move_name}$|\\n{move_name}$|^{move_name}\\n|\\n{move_name}\\n\"\n",
    "    )\n",
    "    move_name_check: pandas.Series = df[move_column_name].str.contains(\n",
    "        move_name, flags=re.IGNORECASE\n",
    "    )\n",
    "    # Check if the character name is the same, case insensitive\n",
    "    character_name_check: pandas.Series = df[\"Character\"].str.contains(\n",
    "        character_name, flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    if move_name_check.any() == False:\n",
    "\n",
    "        logger.debug(f\"Move [{move_name}] not found, checking alternate names\")\n",
    "\n",
    "        move_name_check = df[\"Alt Names\"].str.contains(\n",
    "            alt_names_regex, flags=re.IGNORECASE\n",
    "        )\n",
    "\n",
    "    result_df: pandas.DataFrame = df[move_name_check & character_name_check]\n",
    "\n",
    "    if result_df.empty:\n",
    "        logger.debug(f\"Move [{move_name}] not found for character [{character_name}]\")\n",
    "        return pandas.DataFrame()\n",
    "    else:\n",
    "        logger.debug(f\"Move [{move_name}] found for character [{character_name}]\")\n",
    "        return result_df\n",
    "\n",
    "\n",
    "def get_frame_data_for_move(move_name: str, df) -> pandas.DataFrame:\n",
    "    # Get the frame data for a single move, given a move name and a dataframe\n",
    "\n",
    "    logger.debug(f\"Getting frame data for move [{move_name}]\")\n",
    "\n",
    "    generic_move_name_regex: str = r\"(.*?)([lmh])([pk])\"\n",
    "    repeat_moves_regex: str = r\"[Xx](\\d+)$\"\n",
    "\n",
    "    data_for_move: pandas.DataFrame = find_move_from_name_and_character(\n",
    "        move_name, character_name, df\n",
    "    )\n",
    "    repeat_search: re.Match[str] | None = re.search(\n",
    "        repeat_moves_regex, move_name, re.IGNORECASE\n",
    "    )\n",
    "    if not repeat_search:\n",
    "        # if the move name contains an x or X followed by a number, it is a repeat move (e.g 5MKx2)\n",
    "        logger.debug(f\"Move [{move_name}] is a repeat move\")\n",
    "\n",
    "        # get the move name without the repeat count and set the move name to that\n",
    "        move_name_without_repeat_count: str = re.sub(repeat_moves_regex, \"\", move_name)\n",
    "\n",
    "        # get the frame data for the move without the repeat count\n",
    "        data_for_move_without_repeat_count: pandas.DataFrame = (\n",
    "            find_move_from_name_and_character(\n",
    "                move_name_without_repeat_count, character_name, df\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if data_for_move_without_repeat_count.any:\n",
    "            # if the move without the repeat count is found, get next x normals in the sequence where x is the repeat count -1\n",
    "            # eg if the move is 5HPx3, get the frame data for 5HP, then get the frame data for 5HPx2 and 5HPx3\n",
    "            for i in (\n",
    "                range(int(repeat_search.group(1)) - 1) if repeat_search else range(0)\n",
    "            ):\n",
    "                temp_move_name: str = move_name_without_repeat_count + \"X\" + str(i + 1)\n",
    "                data_for_move = concatenate_dataframes(\n",
    "                    data_for_move,\n",
    "                    find_move_from_name_and_character(\n",
    "                        temp_move_name, character_name, df\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "    # if the move name is not in the frame data dataframe, check if it has an alias\n",
    "    if data_for_move.empty:\n",
    "\n",
    "        logger.debug(f\"Move name not found, checking aliases\")\n",
    "\n",
    "        # try to get the alias move name\n",
    "        move_name_alias: str = get_alias_move(move_name)\n",
    "\n",
    "        # if the alias move name is not empty, get the frame data for the alias move name\n",
    "        if move_name_alias != \"\":\n",
    "            logger.debug(f\"Alias for [{move_name}] found as [{move_name_alias}]\")\n",
    "            data_for_move = find_move_from_name_and_character(\n",
    "                move_name_alias, character_name, df\n",
    "            )\n",
    "\n",
    "    # if the move name is not in the frame data dataframe, try to find a generic form of the move name in the frame data dataframe\n",
    "    elif data_for_move.empty and re.search(generic_move_name_regex, move_name):\n",
    "\n",
    "        logger.debug(\n",
    "            f\"Move [{move_name}] not found, checking generic move names for matches\"\n",
    "        )\n",
    "\n",
    "        # search for the generic move name in the frame data dataframe\n",
    "        match: re.Match[str] | None = re.search(\n",
    "            generic_move_name_regex, move_name, flags=re.IGNORECASE\n",
    "        )\n",
    "\n",
    "        # if the generic move name is found\n",
    "        if match:\n",
    "\n",
    "            # get the generic move name\n",
    "            generic_move_name: str = match.group(1) + match.group(3)\n",
    "\n",
    "            # search for the generic move name in the frame data dataframe\n",
    "            logger.debug(f\"Data for move [{move_name}] found as [{generic_move_name}]\")\n",
    "            data_for_move = find_move_from_name_and_character(\n",
    "                generic_move_name, character_name, df\n",
    "            )\n",
    "\n",
    "    # if the move name is not in the frame data dataframe, log that the move was not found\n",
    "    if data_for_move.empty:\n",
    "\n",
    "        logger.warning(f\"Move {move_name} not found\")\n",
    "\n",
    "        # return an empty dataframe with the same columns as the frame data dataframe\n",
    "        data_for_move: pandas.DataFrame = pandas.DataFrame(columns=df.columns)\n",
    "\n",
    "    # return the dataframe with the move data\n",
    "    return data_for_move\n",
    "\n",
    "\n",
    "def get_alias_move(move_name: str) -> str:\n",
    "\n",
    "    # get all move name aliases that contain the given move name\n",
    "    alias_df: pandas.DataFrame = move_name_alias_df[\n",
    "        move_name_alias_df[\"Value\"].str.contains(\n",
    "            move_name, na=False, flags=re.IGNORECASE\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # return the alias if it exists\n",
    "    return alias_df[\"Key\"].iloc[0] if not alias_df.empty else \"\"\n",
    "\n",
    "\n",
    "def get_frame_data_for_combo(combo_df: pandas.DataFrame) -> pandas.DataFrame:\n",
    "\n",
    "    # initialize an empty frame data pandas.DataFrame\n",
    "    combo_framedata_df: pandas.DataFrame = pandas.DataFrame(\n",
    "        columns=full_framedata_df.columns\n",
    "    )\n",
    "\n",
    "    # get the combo moves from the given combo pandas.DataFrame\n",
    "    combo_moves: pandas.Series[str] = combo_df[move_column_name]\n",
    "\n",
    "    # loop through each move in the combo\n",
    "    for move in combo_moves:\n",
    "        # skip empty strings or strings with only spaces\n",
    "        if move == \"\" or move.isspace():\n",
    "            continue\n",
    "        move.strip()\n",
    "        # get the frame data for the current move\n",
    "        move_framedata: pandas.DataFrame = get_frame_data_for_move(\n",
    "            move, full_framedata_df\n",
    "        )\n",
    "\n",
    "        # append the move frame data to the temporary frame data pandas.DataFrame\n",
    "        combo_framedata_df = concatenate_dataframes(combo_framedata_df, move_framedata)\n",
    "\n",
    "    return combo_framedata_df\n",
    "\n",
    "\n",
    "combo_framedata_df: pandas.DataFrame = get_frame_data_for_combo(combo_framedata_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxUndizzy: int = 240\n",
    "damageScaling: float = 0.875\n",
    "damageScalingMin: float = 0.2\n",
    "# damage scaling minimum for attacks with over 1000 base damage\n",
    "damageScalingMinBigHit: float = 0.275\n",
    "# all hits after the 3rd hit are scaled compundingly by 0.875\n",
    "# the minimum damage scaling is 0.2\n",
    "# the minimum damage scaling for attacks with over 1000 base damage is 0.275\n",
    "# function to calculate the damage scaling for a hit\n",
    "\n",
    "\n",
    "def parse_hits(combo_frame_data_df) -> pandas.DataFrame:\n",
    "    # Set up the regex to find the number of hits in a move\n",
    "    num_hits_regex: str = r\"(\\d+)x(\\d+)$\"\n",
    "    # Set up the dataframe for the hits\n",
    "    hits_df: pandas.DataFrame = pandas.DataFrame(\n",
    "        columns=[\"Move Name\", \"Damage\", \"Chip\", \"Special\"]\n",
    "    )\n",
    "\n",
    "    for move in combo_frame_data_df[\"Move Name\"]:\n",
    "        # If the move is a kara, remove the last move from the dataframe as it was not hit\n",
    "        if move == \"kara\":\n",
    "            hits_df.drop(hits_df.tail(1).index, inplace=True)\n",
    "            continue\n",
    "\n",
    "        # If the move does not have any damage, continue to the next move\n",
    "        if pandas.isna(\n",
    "            combo_frame_data_df.loc[\n",
    "                combo_frame_data_df[\"Move Name\"] == move, \"Damage\"\n",
    "            ].iloc[0]\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        # Initialize the lists for the damage, chip, and special properties of the move\n",
    "        move_damage: list = []\n",
    "        move_chip: list = []\n",
    "        move_special: list = []\n",
    "\n",
    "        # Get the damage list for the current move\n",
    "        currentmove_damagestr: str = combo_frame_data_df.loc[\n",
    "            combo_frame_data_df[\"Move Name\"] == move, \"Damage\"\n",
    "        ].iloc[0]\n",
    "\n",
    "        # Extract the chip properties from the damage list and remove them from the list\n",
    "        extract_values_from_parentheses(move_chip, currentmove_damagestr)\n",
    "        # Extract the special properties from the damage list and remove them from the list\n",
    "        extract_values_from_brackets(move_special, currentmove_damagestr)\n",
    "\n",
    "        # Initialize the list of the damage done by the move\n",
    "        currentmove_damagelist: list = currentmove_damagestr.split(\",\")\n",
    "\n",
    "        # for every element in the list of the move's damage values\n",
    "        hits_df = clean_and_extract_damage(\n",
    "            num_hits_regex, hits_df, move, move_damage, currentmove_damagelist\n",
    "        )\n",
    "    return hits_df\n",
    "\n",
    "\n",
    "def clean_and_extract_damage(\n",
    "    num_hits_regex, hits_df: pandas.DataFrame, move, move_dmg, curr_dmg_list\n",
    ") -> pandas.DataFrame:\n",
    "    for i in range(len(curr_dmg_list)):\n",
    "        # if the string is empty, skip it\n",
    "        if curr_dmg_list[i] == \"\":\n",
    "            continue\n",
    "            # remove whitespace\n",
    "        curr_dmg_list[i] = re.sub(r\"\\s\", \"\", curr_dmg_list[i])\n",
    "        if curr_dmg_list[i] == \"\":\n",
    "            continue\n",
    "            # search for a match to the regex pattern for the number of hits and damage\n",
    "        numhits_result: re.Match[str] | None = re.search(\n",
    "            num_hits_regex, curr_dmg_list[i]\n",
    "        )\n",
    "        # if the regex pattern is found, extract the damage and number of hits\n",
    "        if numhits_result:\n",
    "            numhits: int = int(numhits_result.group(2))\n",
    "            hitdmg: int = int(numhits_result.group(1))\n",
    "            # add the damage for each hit to the move's damage list\n",
    "            for j in range(numhits):\n",
    "                move_dmg.append(hitdmg)\n",
    "                # add the damage to a temporary pandas.DataFrame\n",
    "                temp_df: pandas.DataFrame = pandas.DataFrame(\n",
    "                    [[move, hitdmg, None, None]],\n",
    "                    columns=hits_df.columns,\n",
    "                )\n",
    "                # append the temporary pandas.DataFrame to the hits pandas.DataFrame\n",
    "                pandas.concat([hits_df, temp_df], ignore_index=True)\n",
    "\n",
    "            # if the regex pattern is not found and the string is not empty, add it directly to the move's damage list\n",
    "        if curr_dmg_list[i] != \"\" and not re.search(num_hits_regex, curr_dmg_list[i]):\n",
    "            move_dmg.append(curr_dmg_list[i])\n",
    "            # add the damage to a temporary pandas.DataFrame\n",
    "            temp_df: pandas.DataFrame = pandas.DataFrame(\n",
    "                [[move, curr_dmg_list[i], None, None]],\n",
    "                columns=hits_df.columns,\n",
    "            )\n",
    "            # append the temporary pandas.DataFrame to the hits pandas.DataFrame\n",
    "            pandas.concat([hits_df, temp_df], ignore_index=True)\n",
    "        logger.info(f\"moveDamage: {move_dmg}\")\n",
    "    return hits_df\n",
    "\n",
    "\n",
    "def extract_values_from_brackets(l: list, s: str) -> str:\n",
    "    S: str = s\n",
    "    # Define the regex pattern to search for\n",
    "    bracket_regex: str = r\"\\[.+\\]\"\n",
    "    # Search for the regex pattern in the string\n",
    "    if re.search(bracket_regex, s):\n",
    "        # If found, return a Match object\n",
    "        r: re.Match[str] | None = re.search(bracket_regex, s)\n",
    "        # Append the match to the list\n",
    "        if r:\n",
    "            l.append(r.group(0))\n",
    "        # Remove the regex pattern from the string\n",
    "        S: str = re.sub(bracket_regex, \"\", s)\n",
    "        # Log the list and string\n",
    "        logger.debug(l)\n",
    "        logger.debug(S)\n",
    "    # Return the string\n",
    "    return S\n",
    "\n",
    "\n",
    "def extract_values_from_parentheses(l: list, s: str) -> str:\n",
    "    S: str = s\n",
    "    # define regex for parentheses\n",
    "    parentheses_regex: str = r\"\\(.+\\)\"\n",
    "    # check if regex is found in string\n",
    "    if re.search(parentheses_regex, s):\n",
    "        # assign match to variable\n",
    "        r: re.Match[str] | None = re.search(parentheses_regex, s)\n",
    "        # append string inside parentheses to list\n",
    "        if r:\n",
    "            l.append(r.group(0))\n",
    "        # remove parentheses and string from string\n",
    "        S: str = re.sub(parentheses_regex, \"\", s)\n",
    "        logger.debug(l)\n",
    "        logger.debug(S)\n",
    "    return S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-23 14:15:17 ['(35)']\n",
      "2023-02-23 14:15:17 250, [300 ]\n",
      "2023-02-23 14:15:17 ['[300 (35)]']\n",
      "2023-02-23 14:15:17 250, \n",
      "2023-02-23 14:15:17 moveDamage: ['250']\n",
      "2023-02-23 14:15:17 moveDamage: ['250', '[300(35)]']\n",
      "2023-02-23 14:15:17 ['(45)']\n",
      "2023-02-23 14:15:17 500, [450 ]\n",
      "2023-02-23 14:15:17 ['[450 (45)]']\n",
      "2023-02-23 14:15:17 500, \n",
      "2023-02-23 14:15:17 moveDamage: ['500']\n",
      "2023-02-23 14:15:17 moveDamage: ['500', '[450(45)]']\n",
      "2023-02-23 14:15:17 ['(45 x3)']\n",
      "2023-02-23 14:15:17 700, [450 x3 ]\n",
      "2023-02-23 14:15:17 ['[450 x3 (45 x3)]']\n",
      "2023-02-23 14:15:17 700, \n",
      "2023-02-23 14:15:17 moveDamage: ['700']\n",
      "2023-02-23 14:15:17 moveDamage: ['700', '[450x3(45x3)]']\n",
      "2023-02-23 14:15:17 ['(70)']\n",
      "2023-02-23 14:15:17 600, [650 ]\n",
      "2023-02-23 14:15:17 ['[650 (70)]']\n",
      "2023-02-23 14:15:17 600, \n",
      "2023-02-23 14:15:17 moveDamage: ['600']\n",
      "2023-02-23 14:15:17 moveDamage: ['600', '[650(70)]']\n",
      "2023-02-23 14:15:17 ['(40 x23)']\n",
      "2023-02-23 14:15:17 280 x23 \n",
      "2023-02-23 14:15:17 moveDamage: ['280x23(40x23)']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 108\u001b[0m\n\u001b[0;32m    103\u001b[0m             damage_undizzy_table\u001b[39m.\u001b[39mat[hit, \u001b[39m\"\u001b[39m\u001b[39mTotal Damage For Move\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m move_damage\n\u001b[0;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m damage_undizzy_table\n\u001b[1;32m--> 108\u001b[0m damage: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m get_combo_damage(combo_framedata_df)\n\u001b[0;32m    109\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDamage: \u001b[39m\u001b[39m{\u001b[39;00mdamage\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mget_combo_damage\u001b[1;34m(combo_frame_data_df)\u001b[0m\n\u001b[0;32m     50\u001b[0m         table_undizzy_damage\u001b[39m.\u001b[39mat[i, \u001b[39m\"\u001b[39m\u001b[39mHit Number\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (\n\u001b[0;32m     51\u001b[0m             table_undizzy_damage\u001b[39m.\u001b[39mat[i \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mHit Number\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     52\u001b[0m         )\n\u001b[0;32m     54\u001b[0m \u001b[39m# add the damage scaling for each hit, based on the hit number column and the damage column\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m table_undizzy_damage[\u001b[39m\"\u001b[39;49m\u001b[39mDamageScaling\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m=\u001b[39m table_undizzy_damage\u001b[39m.\u001b[39mapply(\n\u001b[0;32m     56\u001b[0m     \u001b[39mlambda\u001b[39;00m row: get_damage_scaling_for_hit(row[\u001b[39m\"\u001b[39m\u001b[39mHit Number\u001b[39m\u001b[39m\"\u001b[39m], row[\u001b[39m\"\u001b[39m\u001b[39mDamage\u001b[39m\u001b[39m\"\u001b[39m]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     59\u001b[0m \u001b[39m# calculate the real damage for each hit rounded down\u001b[39;00m\n\u001b[0;32m     60\u001b[0m table_undizzy_damage[\u001b[39m\"\u001b[39m\u001b[39mScaled Damage\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m table_undizzy_damage\u001b[39m.\u001b[39mapply(\n\u001b[0;32m     61\u001b[0m     \u001b[39mlambda\u001b[39;00m row: math\u001b[39m.\u001b[39mfloor(row[\u001b[39m\"\u001b[39m\u001b[39mDamage\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m*\u001b[39m row[\u001b[39m\"\u001b[39m\u001b[39mDamageScaling\u001b[39m\u001b[39m\"\u001b[39m]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     62\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:3970\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array(key, value)\n\u001b[0;32m   3969\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m-> 3970\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item_frame_value(key, value)\n\u001b[0;32m   3971\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[0;32m   3972\u001b[0m     is_list_like(value)\n\u001b[0;32m   3973\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique\n\u001b[0;32m   3974\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mget_indexer_for([key])) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(value)\n\u001b[0;32m   3975\u001b[0m ):\n\u001b[0;32m   3976\u001b[0m     \u001b[39m# Column to set is duplicated\u001b[39;00m\n\u001b[0;32m   3977\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:4100\u001b[0m, in \u001b[0;36mDataFrame._set_item_frame_value\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4098\u001b[0m len_cols \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m is_scalar(cols) \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(cols)\n\u001b[0;32m   4099\u001b[0m \u001b[39mif\u001b[39;00m len_cols \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(value\u001b[39m.\u001b[39mcolumns):\n\u001b[1;32m-> 4100\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mColumns must be same length as key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   4102\u001b[0m \u001b[39m# align right-hand-side columns if self.columns\u001b[39;00m\n\u001b[0;32m   4103\u001b[0m \u001b[39m# is multi-index and self[key] is a sub-frame\u001b[39;00m\n\u001b[0;32m   4104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[0;32m   4105\u001b[0m     loc, (\u001b[39mslice\u001b[39m, Series, np\u001b[39m.\u001b[39mndarray, Index)\n\u001b[0;32m   4106\u001b[0m ):\n",
      "\u001b[1;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "def get_damage_scaling_for_hit(hit_num: int, d: int) -> float:\n",
    "    # convert the damage to an int\n",
    "    damage: int = int(d)\n",
    "    # check if the damage is 0 -0 or none\n",
    "    if damage == 0 or damage == -0:\n",
    "        # return the damage scaling for the hit before, as the hit did no damage\n",
    "        return max(damageScalingMin, damageScaling ** (hit_num - 4))\n",
    "\n",
    "    if hit_num <= 3:\n",
    "        return 1\n",
    "    # check if the damage is greater than 1000\n",
    "    if damage >= 1000:\n",
    "        return max(damageScalingMinBigHit, damageScaling ** (hit_num - 3))\n",
    "    else:\n",
    "        return max(damageScalingMin, damageScaling ** (hit_num - 3))\n",
    "\n",
    "\n",
    "def get_combo_damage(combo_frame_data_df) -> int:\n",
    "    # undizzy values for each hit level are 15,30,40,30,0\n",
    "\n",
    "    table_undizzy: pandas.DataFrame = pandas.DataFrame(\n",
    "        columns=[\"Light\", \"Medium\", \"Heavy\", \"Special\", \"Throws+Supers\"]\n",
    "    )\n",
    "    # add the undizzy values to the table\n",
    "    table_undizzy.loc[0] = [15, 30, 40, 30, 0]  # type: ignore\n",
    "\n",
    "    # create a new table to store the damage and undizzy values for each hit\n",
    "    table_undizzy_damage: pandas.DataFrame = pandas.DataFrame(\n",
    "        columns=[\n",
    "            \"Move Name\",\n",
    "            \"Hit Number\",\n",
    "            \"Damage\",\n",
    "            \"DamageScaling\",\n",
    "            \"Scaled Damage\",\n",
    "            \"Undizzy\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    df_newhits: pandas.DataFrame = parse_hits(combo_frame_data_df)\n",
    "\n",
    "    # add the newHits table to the damageAndUndizzyTable\n",
    "    table_undizzy_damage = pandas.concat(\n",
    "        [table_undizzy_damage, df_newhits], ignore_index=True\n",
    "    )\n",
    "    # Add a column for the hit number\n",
    "    # Hit number goes up for each non-zero damage hit\n",
    "\n",
    "    for i in range(len(table_undizzy_damage)):\n",
    "        if table_undizzy_damage.at[i, \"Damage\"] > 0:\n",
    "            table_undizzy_damage.at[i, \"Hit Number\"] = (\n",
    "                table_undizzy_damage.at[i - 1, \"Hit Number\"] + 1\n",
    "            )\n",
    "\n",
    "    # add the damage scaling for each hit, based on the hit number column and the damage column\n",
    "    table_undizzy_damage[\"DamageScaling\"] = table_undizzy_damage.apply(\n",
    "        lambda row: get_damage_scaling_for_hit(row[\"Hit Number\"], row[\"Damage\"]), axis=1\n",
    "    )\n",
    "\n",
    "    # calculate the real damage for each hit rounded down\n",
    "    table_undizzy_damage[\"Scaled Damage\"] = table_undizzy_damage.apply(\n",
    "        lambda row: math.floor(row[\"Damage\"] * row[\"DamageScaling\"]), axis=1\n",
    "    )\n",
    "    # calculate the total damage for the combo for each hit by summing all previous hits\n",
    "    table_undizzy_damage[\"Total Damage\"] = table_undizzy_damage[\n",
    "        \"Scaled Damage\"\n",
    "    ].cumsum()\n",
    "    # set the hit number to the index of the row\n",
    "    table_undizzy_damage[\"Hit Number\"] = table_undizzy_damage.index + 1\n",
    "    total_damage: int = table_undizzy_damage[\"Scaled Damage\"].sum()\n",
    "    total_damage_for_moves(table_undizzy_damage)\n",
    "    logger.info(table_undizzy_damage)\n",
    "    return total_damage\n",
    "\n",
    "\n",
    "def total_damage_for_moves(damage_undizzy_table: pandas.DataFrame) -> pandas.DataFrame:\n",
    "    # add a new column to the df to store the total damage for each move\n",
    "    damage_undizzy_table.at[:, \"Total Damage For Move\"] = 0\n",
    "    move_damage: int = 0\n",
    "    # loop through each row in the df\n",
    "    for hit in range(len(damage_undizzy_table)):\n",
    "\n",
    "        move_name: str = damage_undizzy_table.at[hit, \"Move Name\"]\n",
    "\n",
    "        # add the damage to the total damage for the move\n",
    "        move_damage += damage_undizzy_table.at[hit, \"Scaled Damage\"]\n",
    "        move_damage += 1\n",
    "\n",
    "        # if it's not the last row and the next row has a different move name\n",
    "        if (\n",
    "            hit < len(damage_undizzy_table) - 1\n",
    "            and move_name != damage_undizzy_table.at[hit + 1, \"Move Name\"]\n",
    "        ):\n",
    "\n",
    "            # add the total damage for the move to the damageAndUndizzyTable at the location of the first hit of the move\n",
    "            damage_undizzy_table.at[hit, \"Total Damage For Move\"] = move_damage\n",
    "\n",
    "            # reset the total damage and hits for the move\n",
    "            move_damage = 0\n",
    "\n",
    "        # if it's the last row, add the total damage and hits for the last move to table\n",
    "        elif hit == len(damage_undizzy_table) - 1:\n",
    "            # add the total damage and hits for the last move to table\n",
    "            damage_undizzy_table.at[hit, \"Total Damage For Move\"] = move_damage\n",
    "\n",
    "    return damage_undizzy_table\n",
    "\n",
    "\n",
    "damage: int = get_combo_damage(combo_framedata_df)\n",
    "print(f\"Damage: {damage}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a8c00dd9af4e1c93e4338362a27a62462f0e60bdb92fa770fcc27a8ee26261a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
