{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from asyncio.log import logger\n",
    "import math\n",
    "from os import stat\n",
    "from random import choice\n",
    "import re\n",
    "from shutil import move\n",
    "import pandas\n",
    "import inspect\n",
    "import numpy\n",
    "import re as regex\n",
    "import logging\n",
    "import sys\n",
    "import typing\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# For testing the damage calc in this stage, I want to check against a folder full of csvs\n",
    "\n",
    "def get_csv_list(path: str) -> list[str]:\n",
    "    \"\"\"Returns a list of all csv files in a given path with their relative path\"\"\"\n",
    "    return [os.path.join(path, f) for f in os.listdir(path) if f.endswith(\".csv\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_df_copy_columns(df: pandas.DataFrame) -> pandas.DataFrame:\n",
    "    \"\"\"Creates a copy of a dataframe with the same columns\"\"\"\n",
    "    copy_df: pandas.DataFrame = pandas.DataFrame(columns=df.columns)\n",
    "    return copy_df\n",
    "\n",
    "\n",
    "def get_character_name() -> str:\n",
    "    return comboInputDf.iloc[0][\"Character\"]\n",
    "\n",
    "\n",
    "# get the expected damage for the combo, first value in the third column of the combo csv\n",
    "def get_expected_damage() -> int:\n",
    "    return comboInputDf.iloc[0][\"Expected Damage\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the character column in the comboDf to the character name\n",
    "def set_column_value(df: pandas.DataFrame, column: str, value: str) -> None:\n",
    "    logger.debug(f\"Setting {column} to {value}\")\n",
    "    df[column] = value\n",
    "\n",
    "\n",
    "def split_columns(df: pandas.DataFrame, column_name,\n",
    "                  seperator) -> pandas.DataFrame:\n",
    "    splitdf = df.copy()\n",
    "    # split the values in a column on a given seperator\n",
    "    logger.debug(f'Splitting {column_name} on \"{seperator}\"')\n",
    "    splitdf[column_name] = splitdf[column_name].str.split(seperator)\n",
    "    # explode the column so that each value is on a row\n",
    "    splitdf: pandas.DataFrame = splitdf.explode(column_name)\n",
    "    return splitdf\n",
    "\n",
    "\n",
    "def concatenate_dataframes(df, inputdf) -> pandas.DataFrame:\n",
    "    # Concatenates two dataframes\n",
    "    return pandas.concat([df, inputdf], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_move_from_name_and_character(\n",
    "        move_name: str, character_name: str,\n",
    "        df: pandas.DataFrame) -> pandas.DataFrame:\n",
    "    \"\"\"Find a move from the move name and character name\n",
    "\n",
    "    Args:\n",
    "        move_name (str): The name of the move\n",
    "        character_name (str): The name of the character\n",
    "        df (pandas.DataFrame): The dataframe containing the move data\n",
    "    Returns:\n",
    "        pandas.DataFrame: The dataframe containing the move data\n",
    "    \"\"\"\n",
    "\n",
    "    # logger.debug(f\"Searching for [{move_name}] for character [{character_name}]\")\n",
    "\n",
    "    name_regex: str = rf\"^{move_name}$|\\n{move_name}$|^{move_name}\\n|\\n{move_name}\\n\"\n",
    "\n",
    "    # Check if the character name is the same, case insensitive\n",
    "    character_check: pandas.Series[bool] = df[\"Character\"].str.contains(\n",
    "        character_name, flags=re.IGNORECASE)\n",
    "\n",
    "    # Check if the move name is in either column, case insensitive\n",
    "    move_check: pandas.Series[bool] = df[\"Move Name\"].str.contains(\n",
    "        name_regex, flags=re.IGNORECASE)\n",
    "    if not move_check.any():\n",
    "        # if the move name is not found, check the alias column\n",
    "        move_check: pandas.Series[bool] = df[\"Alt Names\"].str.contains(\n",
    "            name_regex, flags=re.IGNORECASE)\n",
    "\n",
    "    result: pandas.DataFrame = df[move_check & character_check]\n",
    "\n",
    "    if result.empty:\n",
    "        return pandas.DataFrame()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def get_frame_data_for_move(move_name: str, df: pandas.DataFrame) -> pandas.DataFrame:\n",
    "    # Get the frame data for a single move, given a move name and a dataframe\n",
    "\n",
    "    logger.debug(\n",
    "        f\"=================\\nGetting frame data for move [{move_name}]\")\n",
    "    # check for follow-up moves such as 214HP~P or QCBLP P or 214 MP,P etc\n",
    "    # regex that matches L, M or H, followed by P or K followed by \"~\", \",\", \"+\" or \" \" followed by P or K\n",
    "    follow_up_move_regex: str = r\"(.+[lmh]?[pk])([~\\+,\\s]){1,3}([pk])\"\n",
    "    # search for the follow-up move in the move name case insensitive\n",
    "    follow_up_move_search: re.Match[str] | None = re.search(\n",
    "        follow_up_move_regex, move_name, re.IGNORECASE)\n",
    "\n",
    "    if follow_up_move_search:\n",
    "        # if the move name contains a follow-up move, get the frame data for the follow-up move\n",
    "        logger.debug(f\"Move [{move_name}] is a follow-up move\")\n",
    "\n",
    "        # get the frame data for the follow-up move\n",
    "        data_to_add, move_name = find_base_move_data_for_followup_move(\n",
    "            move_name, df, follow_up_move_search)\n",
    "    else:\n",
    "        data_to_add: pandas.DataFrame = pandas.DataFrame()\n",
    "\n",
    "    generic_move_name_regex: str = r\"(.*?)([lmh])([pk])\"\n",
    "    repeat_moves_regex: str = r\"[Xx](\\d+)$\"\n",
    "\n",
    "    data_for_move: pandas.DataFrame = find_move_from_name_and_character(move_name,\n",
    "                                                                        character_name, df)\n",
    "\n",
    "    # if the move name is not in the frame data dataframe, check if it is a repeat move\n",
    "    repeat_search: re.Match[str] | None = re.search(repeat_moves_regex,\n",
    "                                                    move_name, re.IGNORECASE)\n",
    "    if repeat_search:\n",
    "        # if the move name contains an x or X followed by a number, it is a repeat move (e.g 5MKx2)\n",
    "        logger.debug(f\"Move [{move_name}] is a repeat move\")\n",
    "\n",
    "        # get the move name without the repeat count and set the move name to that\n",
    "        data_for_move = find_repeat_move_data(move_name, df,\n",
    "                                              repeat_moves_regex,\n",
    "                                              repeat_search)\n",
    "\n",
    "    # if the move name is not in the frame data dataframe, check if it has an alias\n",
    "    if data_for_move.empty:\n",
    "\n",
    "        logger.debug(f\"Move name not found, checking aliases\")\n",
    "\n",
    "        # try to get the alias move name\n",
    "        data_for_move = find_alias_move_data(move_name, df)\n",
    "\n",
    "    # if the move name is not in the frame data dataframe, try to find a generic form of the move name in the frame data dataframe\n",
    "    elif data_for_move.empty and re.search(generic_move_name_regex, move_name):\n",
    "\n",
    "        logger.debug(\n",
    "            f\"Move [{move_name}] not found, checking generic move names for matches\"\n",
    "        )\n",
    "\n",
    "        # search for the generic move name in the frame data dataframe\n",
    "        data_for_move = find_generic_move_data(\n",
    "            move_name, df, generic_move_name_regex)\n",
    "\n",
    "    # if the move name is not in the frame data dataframe, log that the move was not found\n",
    "    if data_for_move.empty:\n",
    "\n",
    "        logger.warning(f\"Move {move_name} not found\")\n",
    "\n",
    "        # return an empty dataframe with the same columns as the frame data dataframe\n",
    "        data_for_move: pandas.DataFrame = pandas.DataFrame(columns=df.columns)\n",
    "    else:\n",
    "        if not data_to_add.empty:\n",
    "            # if the move is a follow-up move, add the frame data for the follow-up move to the dataframe\n",
    "            data_for_move = pandas.concat([data_for_move, data_to_add])\n",
    "\n",
    "    # return the dataframe with the move data\n",
    "    return data_for_move\n",
    "\n",
    "\n",
    "def find_generic_move_data(move_name: str, df: pandas.DataFrame, generic_move_name_regex: str) -> pandas.DataFrame:\n",
    "\n",
    "    match: re.Match[str] | None = re.search(generic_move_name_regex,\n",
    "                                            move_name,\n",
    "                                            flags=re.IGNORECASE)\n",
    "\n",
    "    # if the generic move name is found\n",
    "    if match:\n",
    "        # get the generic move name\n",
    "        generic_move_name: str = match.group(1) + match.group(3)\n",
    "\n",
    "        # search for the generic move name in the frame data dataframe\n",
    "        logger.debug(\n",
    "            f\"Data for move [{move_name}] found as [{generic_move_name}]\")\n",
    "        data_for_move: pandas.DataFrame = find_move_from_name_and_character(\n",
    "            generic_move_name, character_name, df)\n",
    "    else:\n",
    "        data_for_move: pandas.DataFrame = pandas.DataFrame()\n",
    "\n",
    "    return data_for_move\n",
    "\n",
    "\n",
    "def find_alias_move_data(move_name: str,\n",
    "                         df: pandas.DataFrame) -> pandas.DataFrame:\n",
    "    move_name_alias: str = get_alias_move(move_name)\n",
    "\n",
    "    # if the alias move name is not empty, get the frame data for the alias move name\n",
    "    if move_name_alias != \"\":\n",
    "        logger.debug(f\"Alias for [{move_name}] found as [{move_name_alias}]\")\n",
    "        data_for_move: pandas.DataFrame = find_move_from_name_and_character(\n",
    "            move_name_alias, character_name, df)\n",
    "    else:\n",
    "        data_for_move: pandas.DataFrame = pandas.DataFrame()\n",
    "\n",
    "    return data_for_move\n",
    "\n",
    "\n",
    "def find_repeat_move_data(\n",
    "    move_name: str,\n",
    "    df: pandas.DataFrame,\n",
    "    repeat_moves_regex: str,\n",
    "    repeat_search: re.Match[str] | None,\n",
    ") -> pandas.DataFrame:\n",
    "\n",
    "    move_name_without_repeat_count: str = re.sub(repeat_moves_regex, \"\",\n",
    "                                                 move_name)\n",
    "\n",
    "    # get the frame data for the move without the repeat count\n",
    "    data_for_move_without_repeat_count: pandas.DataFrame = (\n",
    "        find_move_from_name_and_character(move_name_without_repeat_count,\n",
    "                                          character_name, df))\n",
    "\n",
    "    if data_for_move_without_repeat_count.any:\n",
    "        data_for_move: pandas.DataFrame = data_for_move_without_repeat_count\n",
    "        # if the move without the repeat count is found, get next x normals in the sequence where x is the repeat count -1\n",
    "        # eg if the move is 5HPx3, get the frame data for 5HP, then get the frame data for 5HPx2 and 5HPx3\n",
    "        logger.debug(f\"Found data for move [{move_name_without_repeat_count}]\")\n",
    "        for i in range(int(repeat_search.group(1)) -\n",
    "                       1) if repeat_search else range(0):\n",
    "            temp_move_name: str = move_name_without_repeat_count + \"X\" + str(\n",
    "                i + 2)\n",
    "            temp_move_data: pandas.DataFrame = find_move_from_name_and_character(\n",
    "                temp_move_name, character_name, df)\n",
    "\n",
    "            data_for_move = pandas.concat(\n",
    "                [data_for_move, temp_move_data],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "    else:\n",
    "        data_for_move: pandas.DataFrame = pandas.DataFrame()\n",
    "\n",
    "    return data_for_move\n",
    "\n",
    "\n",
    "def find_base_move_data_for_followup_move(\n",
    "    move_name: str,\n",
    "    df: pandas.DataFrame,\n",
    "    follow_up_move_search: re.Match[str]\n",
    ") -> tuple[pandas.DataFrame, str]:\n",
    "    # if the move is a follow-up move, get the frame data for the follow-up move and return the name of the base move and the frame data for the follow-up move\n",
    "    base_move_name: str = follow_up_move_search.group(1)\n",
    "    data_for_move: pandas.DataFrame = find_move_from_name_and_character(\n",
    "        move_name, character_name, df)\n",
    "\n",
    "    return data_for_move, base_move_name\n",
    "\n",
    "\n",
    "def get_alias_move(move_name: str) -> str:\n",
    "\n",
    "    # get all move name aliases that contain the given move name\n",
    "    alias_df: pandas.DataFrame = move_name_alias_df[\n",
    "        move_name_alias_df[\"Value\"].str.contains(move_name,\n",
    "                                                 na=False,\n",
    "                                                 flags=re.IGNORECASE)]\n",
    "\n",
    "    # return the alias if it exists\n",
    "    return alias_df[\"Key\"].iloc[0] if not alias_df.empty else \"\"\n",
    "\n",
    "\n",
    "def get_frame_data_for_combo(combo_df: pandas.DataFrame) -> pandas.DataFrame:\n",
    "\n",
    "    # initialize an empty frame data pandas.DataFrame\n",
    "    combo_framedata_df: pandas.DataFrame = pandas.DataFrame(\n",
    "        columns=full_framedata_df.columns)\n",
    "\n",
    "    # get the combo moves from the given combo pandas.DataFrame\n",
    "    combo_moves: pandas.Series[str] = combo_df[move_column_name]\n",
    "\n",
    "    # loop through each move in the combo\n",
    "    for move in combo_moves:\n",
    "        # skip empty strings or strings with only spaces\n",
    "        if move == \"\" or move.isspace():\n",
    "            continue\n",
    "        move.strip()\n",
    "        # get the frame data for the current move\n",
    "        move_framedata: pandas.DataFrame = get_frame_data_for_move(\n",
    "            move, full_framedata_df)\n",
    "\n",
    "        # append the move frame data to the temporary frame data pandas.DataFrame\n",
    "        combo_framedata_df = concatenate_dataframes(combo_framedata_df,\n",
    "                                                    move_framedata)\n",
    "\n",
    "    return combo_framedata_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_hits(combo_frame_data_df: pandas.DataFrame) -> pandas.DataFrame:\n",
    "    \"\"\"Parse the hits from the combo frame data dataframe.\n",
    "\n",
    "    Args:\n",
    "        combo_frame_data_df (pandas.DataFrame): Combo frame data dataframe.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Hits dataframe. Each row is a hit.\n",
    "    \"\"\"\n",
    "    # Set up the regex to find the number of hits in a move\n",
    "\n",
    "    # Set up the dataframe for the hits\n",
    "    hits_df: pandas.DataFrame = pandas.DataFrame(\n",
    "        columns=[\"Move Name\", \"Damage\", \"Chip\", \"Special\"])\n",
    "\n",
    "    for move in combo_frame_data_df[\"Move Name\"]:\n",
    "        # If the move is a kara, set the damage of the previous move to 0\n",
    "        if move == \"kara\":\n",
    "            logger.debug(\n",
    "                f\"Kara cancel detected, setting damage of previous move to 0\")\n",
    "            # get the location of the move 1 row above the current move\n",
    "            combo_frame_data_df.loc[combo_frame_data_df.index.get_loc(move) -\n",
    "                                    1, \"Damage\"] = 0\n",
    "            continue\n",
    "\n",
    "        # If the move does not have any damage, continue to the next move\n",
    "        damage_check: pandas.DataFrame = combo_frame_data_df.loc[\n",
    "            combo_frame_data_df[\"Move Name\"] == move, \"Damage\"]  # type:ignore\n",
    "        if damage_check.empty or damage_check.iloc[0] == \"\":\n",
    "            continue\n",
    "\n",
    "        # Initialize the lists for the damage, chip, and special properties of the move\n",
    "        move_chip: list[str] = []\n",
    "        move_special: list[str] = []\n",
    "\n",
    "        # Get the damage list for the current move\n",
    "        currentmove_damagestr: str = combo_frame_data_df.loc[\n",
    "            combo_frame_data_df[\"Move Name\"] == move, \"Damage\"].iloc[0]  # type:ignore\n",
    "\n",
    "        # Extract the chip properties from the damage list and remove them from the list\n",
    "        move_chip, currentmove_damagestr = extract_values_from_parentheses(\n",
    "            move_chip, currentmove_damagestr)\n",
    "        # Extract the special properties from the damage list and remove them from the list\n",
    "        move_special, currentmove_damagestr = extract_values_from_brackets(\n",
    "            move_special, currentmove_damagestr)\n",
    "\n",
    "        # Initialize the list of the damage done by the move\n",
    "        currentmove_damagelist: list = currentmove_damagestr.split(\",\")\n",
    "\n",
    "        # clean the damage list and extract the damage, adding a row to the hits dataframe for each hit\n",
    "        hits_df: pandas.DataFrame = clean_and_extract_damage(\n",
    "            hits_df, move, currentmove_damagelist)\n",
    "\n",
    "    return hits_df\n",
    "\n",
    "\n",
    "def clean_and_extract_damage(\n",
    "    hits_df: pandas.DataFrame,\n",
    "    move: str,\n",
    "    dmg_list: list[str],\n",
    ") -> pandas.DataFrame:\n",
    "    \"\"\"Cleans the damage list and extracts the damage, adding a row to the hits dataframe for each hit\n",
    "\n",
    "    Args:\n",
    "        hits_df (pandas.DataFrame): dataframe for hits to be added to\n",
    "        move (str): move name\n",
    "        curr_dmg_list (list[str]): list of damage values for the move to be parsed\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: dataframe with the hits for the move added\n",
    "    \"\"\"\n",
    "\n",
    "    output_df: pandas.DataFrame = hits_df\n",
    "    # Set up the regex to find the number of hits in a move\n",
    "    num_hits_regex: str = r\"(\\d+)x(\\d+)$\"\n",
    "    move_dmg: list[int] = []\n",
    "    # for every element in the list of the move's damage values\n",
    "    for i in range(len(dmg_list)):\n",
    "        # if the string is empty, skip it\n",
    "        if dmg_list[i] == \"\":\n",
    "            continue\n",
    "            # remove whitespace\n",
    "        dmg_list[i] = re.sub(r\"\\s\", \"\", dmg_list[i])\n",
    "        if dmg_list[i] == \"\":\n",
    "            continue\n",
    "            # search for a match to the regex pattern for the number of hits and damage\n",
    "        numhits_result: re.Match[str] | None = re.search(\n",
    "            num_hits_regex, dmg_list[i])\n",
    "        # if the regex pattern is found, extract the damage and number of hits\n",
    "        if numhits_result:\n",
    "            numhits: int = int(numhits_result.group(2))\n",
    "            hitdmg: int = int(numhits_result.group(1))\n",
    "            # add the damage for each hit to the move's damage list\n",
    "            for j in range(numhits):\n",
    "                move_dmg.append(hitdmg)\n",
    "                # add the damage to a temporary pandas.DataFrame\n",
    "                temp_df: pandas.DataFrame = pandas.DataFrame(\n",
    "                    [[move, hitdmg, None, None]],\n",
    "                    columns=output_df.columns,\n",
    "                )\n",
    "                # append the temporary pandas.DataFrame to the hits pandas.DataFrame\n",
    "                output_df: pandas.DataFrame = pandas.concat([output_df, temp_df],\n",
    "                                                            ignore_index=True)\n",
    "\n",
    "            # if the regex pattern is not found and the string is not empty, add it directly to the move's damage list\n",
    "        if dmg_list[i] != \"\" and not re.search(num_hits_regex,\n",
    "                                               dmg_list[i]):\n",
    "            move_dmg.append(int(dmg_list[i]))\n",
    "            # add the damage to a temporary pandas.DataFrame\n",
    "            temp_df: pandas.DataFrame = pandas.DataFrame(\n",
    "                [[move, dmg_list[i], None, None]],\n",
    "                columns=output_df.columns,\n",
    "            )\n",
    "            # append the temporary pandas.DataFrame to the hits pandas.DataFrame\n",
    "            output_df: pandas.DataFrame = pandas.concat([output_df, temp_df],\n",
    "                                                        ignore_index=True)\n",
    "        logger.info(f\"moveDamage: {move_dmg}\")\n",
    "    return output_df\n",
    "\n",
    "\n",
    "def extract_values_from_brackets(l: list[str],\n",
    "                                 s: str) -> tuple[list[str], str]:\n",
    "    \"\"\"Extracts values from a string surrounded by square brackets and removes them from the string\n",
    "\n",
    "    Args:\n",
    "        l (list[str]): list of strings, extracted values will be appended to this list\n",
    "        s (str): string to search for values\n",
    "\n",
    "    Returns:\n",
    "        tuple[list[str], str]: tuple containing the list of extracted values and the string with the values removed\n",
    "    \"\"\"\n",
    "    S: str = s\n",
    "    # Define the regex pattern to search for\n",
    "    bracket_regex: str = r\"\\[.+\\]\"\n",
    "    # Search for the regex pattern in the string\n",
    "    if re.search(bracket_regex, s):\n",
    "        # If found, return a Match object\n",
    "        r: re.Match[str] | None = re.search(bracket_regex, s)\n",
    "        # Append the match to the list\n",
    "        if r:\n",
    "            l.append(r.group(0))\n",
    "        # Remove the regex pattern from the string\n",
    "        S: str = re.sub(bracket_regex, \"\", s)\n",
    "        # Log the list and string\n",
    "        logger.debug(l)\n",
    "        logger.debug(S)\n",
    "    # Return the string\n",
    "    return l, S\n",
    "\n",
    "\n",
    "def extract_values_from_parentheses(l: list[str],\n",
    "                                    s: str) -> tuple[list[str], str]:\n",
    "    \"\"\"Extracts values from a string surrounded by parentheses and removes them from the string\n",
    "\n",
    "    Args:\n",
    "        l (list[str]): list of strings, extracted values will be appended to this list\n",
    "        s (str): string to search for values\n",
    "\n",
    "    Returns:\n",
    "        tuple[list[str], str]: tuple containing the list of extracted values and the string with the values removed\n",
    "    \"\"\"\n",
    "    S: str = s\n",
    "    # define regex for parentheses\n",
    "    parentheses_regex: str = r\"\\(.+\\)\"\n",
    "    # check if regex is found in string\n",
    "    if re.search(parentheses_regex, s):\n",
    "        # assign match to variable\n",
    "        r: re.Match[str] | None = re.search(parentheses_regex, s)\n",
    "        # append string inside parentheses to list\n",
    "        if r:\n",
    "            l.append(r.group(0))\n",
    "        # remove parentheses and string from string\n",
    "        S: str = re.sub(parentheses_regex, \"\", s)\n",
    "        logger.debug(l)\n",
    "        logger.debug(S)\n",
    "    return l, S\n",
    "\n",
    "\n",
    "def get_damage_scaling_for_hit(hit_num: int, d: int) -> float:\n",
    "    # convert the damage to an int\n",
    "    damage: int = int(d)\n",
    "    # check if the damage is 0 -0 or none\n",
    "    if damage == 0 or damage == -0:\n",
    "        # return the damage scaling for the hit before, as the hit did no damage\n",
    "        return max(damageScalingMin, damageScaling**(hit_num - 4))\n",
    "\n",
    "    if hit_num <= 3:\n",
    "        return 1\n",
    "    # check if the damage is greater than 1000\n",
    "    if damage >= 1000:\n",
    "        scaling: float = max(damageScalingMinBigHit,\n",
    "                             damageScaling**(hit_num - 3))\n",
    "    else:\n",
    "        scaling: float = max(damageScalingMin, damageScaling**(hit_num - 3))\n",
    "\n",
    "    # round the damage scaling to 3 decimal places\n",
    "   # scaling: float = round(scaling, 3)\n",
    "    return scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comboInputDf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 154\u001b[0m\n\u001b[0;32m    150\u001b[0m     skombo()\n\u001b[0;32m    153\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 154\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[7], line 150\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m():\n\u001b[1;32m--> 150\u001b[0m     skombo()\n",
      "Cell \u001b[1;32mIn[7], line 103\u001b[0m, in \u001b[0;36mskombo\u001b[1;34m()\u001b[0m\n\u001b[0;32m     99\u001b[0m move_name_alias_df: pandas\u001b[39m.\u001b[39mDataFrame \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mdata/alias.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    101\u001b[0m full_framedata_df: pandas\u001b[39m.\u001b[39mDataFrame \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mdata/frameData.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 103\u001b[0m expected_damage: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m get_expected_damage()\n\u001b[0;32m    105\u001b[0m \u001b[39m# Set some constants\u001b[39;00m\n\u001b[0;32m    106\u001b[0m character_name: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m get_character_name()\n",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m, in \u001b[0;36mget_expected_damage\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_expected_damage\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[1;32m---> 13\u001b[0m     \u001b[39mreturn\u001b[39;00m comboInputDf\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mExpected Damage\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'comboInputDf' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_combo_damage(combo_frame_data_df) -> int:\n",
    "    # undizzy values for each hit level are 15,30,40,30,0\n",
    "\n",
    "    table_undizzy: pandas.DataFrame = pandas.DataFrame(\n",
    "        columns=[\"Light\", \"Medium\", \"Heavy\", \"Special\", \"Throws+Supers\"])\n",
    "    # add the undizzy values to the table\n",
    "    table_undizzy.loc[0] = [15, 30, 40, 30, 0]  # type: ignore\n",
    "\n",
    "    # create a new table to store the damage and undizzy values for each hit\n",
    "    table_undizzy_damage: pandas.DataFrame = pandas.DataFrame(columns=[\n",
    "        \"Move Name\",\n",
    "        \"Hit Number\",\n",
    "        \"Damage\",\n",
    "        \"DamageScaling\",\n",
    "        \"Scaled Damage\",\n",
    "        \"Undizzy\",\n",
    "    ])\n",
    "\n",
    "    df_newhits: pandas.DataFrame = parse_hits(combo_frame_data_df)\n",
    "\n",
    "    # add the newHits table to the damageAndUndizzyTable\n",
    "    table_undizzy_damage = pandas.concat([table_undizzy_damage, df_newhits],\n",
    "                                         ignore_index=True)\n",
    "    # Add a column for the hit number\n",
    "    # Hit number goes up for each non-zero damage hit\n",
    "\n",
    "    for i in range(len(table_undizzy_damage)):\n",
    "        if int(table_undizzy_damage.at[i, \"Damage\"]) > 0:\n",
    "            if i == 0:\n",
    "                table_undizzy_damage.at[i, \"Hit Number\"] = 1\n",
    "            else:\n",
    "                table_undizzy_damage.at[i, \"Hit Number\"] = (\n",
    "                    table_undizzy_damage.at[i - 1, \"Hit Number\"] + 1)\n",
    "\n",
    "    # add the damage scaling for each hit, based on the hit number column and the damage column\n",
    "    table_undizzy_damage[\"DamageScaling\"] = table_undizzy_damage.apply(\n",
    "        lambda row: get_damage_scaling_for_hit(row[\"Hit Number\"], row[\"Damage\"]\n",
    "                                               ),\n",
    "        axis=1)\n",
    "\n",
    "    # calculate the real damage for each hit rounded down\n",
    "    table_undizzy_damage[\"Scaled Damage\"] = table_undizzy_damage.apply(\n",
    "        lambda row: math.floor(float(row[\"Damage\"]) * float(row[\"DamageScaling\"])), axis=1)\n",
    "    # calculate the total damage for the combo for each hit by summing all previous hits\n",
    "    table_undizzy_damage[\"Total Damage\"] = table_undizzy_damage[\n",
    "        \"Scaled Damage\"].cumsum()\n",
    "    # set the hit number to the index of the row\n",
    "    table_undizzy_damage[\"Hit Number\"] = table_undizzy_damage.index + 1\n",
    "    total_damage: int = table_undizzy_damage[\"Scaled Damage\"].sum()\n",
    "    total_damage_for_moves(table_undizzy_damage)\n",
    "    logger.info(table_undizzy_damage)\n",
    "    return total_damage\n",
    "\n",
    "\n",
    "def total_damage_for_moves(\n",
    "        damage_undizzy_table: pandas.DataFrame) -> pandas.DataFrame:\n",
    "    # add a new column to the df to store the total damage for each move\n",
    "    damage_undizzy_table.at[:, \"Total Damage For Move\"] = 0\n",
    "    move_damage: int = 0\n",
    "    # loop through each row in the df\n",
    "    for hit in range(len(damage_undizzy_table)):\n",
    "\n",
    "        move_name: str = damage_undizzy_table.at[hit, \"Move Name\"]\n",
    "\n",
    "        # add the damage to the total damage for the move\n",
    "        move_damage += damage_undizzy_table.at[hit, \"Scaled Damage\"]\n",
    "        move_damage += 1\n",
    "\n",
    "        # if it's not the last row and the next row has a different move name\n",
    "        if (hit < len(damage_undizzy_table) - 1 and\n",
    "                move_name != damage_undizzy_table.at[hit + 1, \"Move Name\"]):\n",
    "\n",
    "            # add the total damage for the move to the damageAndUndizzyTable at the location of the first hit of the move\n",
    "            damage_undizzy_table.at[hit, \"Total Damage For Move\"] = move_damage\n",
    "\n",
    "            # reset the total damage and hits for the move\n",
    "            move_damage = 0\n",
    "\n",
    "        # if it's the last row, add the total damage and hits for the last move to table\n",
    "        elif hit == len(damage_undizzy_table) - 1:\n",
    "            # add the total damage and hits for the last move to table\n",
    "            damage_undizzy_table.at[hit, \"Total Damage For Move\"] = move_damage\n",
    "\n",
    "    return damage_undizzy_table\n",
    "\n",
    "\n",
    "def skombo():\n",
    "    csv_list = get_csv_list(\"data\\combo_csvs\")\n",
    "    \n",
    "    logging.basicConfig(stream=sys.stdout,\n",
    "                        level=logging.DEBUG,\n",
    "                        format=\"%(message)s\")\n",
    "\n",
    "    character_reference_df: pandas.DataFrame = pandas.read_csv(\n",
    "        \"data/characters.csv\")\n",
    "    \n",
    "    move_name_alias_df: pandas.DataFrame = pandas.read_csv(\"data/alias.csv\")\n",
    "    \n",
    "    full_framedata_df: pandas.DataFrame = pandas.read_csv(\"data/frameData.csv\")\n",
    "    \n",
    "    expected_damage: int = get_expected_damage()\n",
    "\n",
    "    # Set some constants\n",
    "    character_name: str = get_character_name()\n",
    "    \n",
    "    move_column_name: str = \"Move Name\"\n",
    "    \n",
    "    # Create an empty dataframe to hold the combo data\n",
    "    # Uses the same columns as tempFrameData\n",
    "    combo_framedata_df: pandas.DataFrame = create_df_copy_columns(\n",
    "        full_framedata_df)\n",
    "\n",
    "    combo_framedata_df = concatenate_dataframes(\n",
    "        combo_framedata_df, split_columns(comboInputDf, move_column_name, \" \"))\n",
    "\n",
    "    # Set the character column in the comboDf to the character name\n",
    "    set_column_value(combo_framedata_df, \"Character\", character_name)\n",
    "\n",
    "    logger.debug(f\"Combo dataframe:\\n{combo_framedata_df}\\n\")\n",
    "\n",
    "    combo_framedata_df: pandas.DataFrame = get_frame_data_for_combo(\n",
    "        combo_framedata_df)\n",
    "\n",
    "    maxUndizzy: int = 240\n",
    "    damageScaling: float = 0.875\n",
    "    damageScalingMin: float = 0.2\n",
    "    # damage scaling minimum for attacks with over 1000 base damage\n",
    "    damageScalingMinBigHit: float = 0.275\n",
    "    # all hits after the 3rd hit are scaled compundingly by 0.875\n",
    "    # the minimum damage scaling is 0.2\n",
    "    # the minimum damage scaling for attacks with over 1000 base damage is 0.275\n",
    "    # function to calculate the damage scaling for a hit\n",
    "\n",
    "    damage: int = get_combo_damage(combo_framedata_df)\n",
    "\n",
    "    logger.debug(f\"Calculated damage: {damage}\")\n",
    "    logger.debug(f\"Expected damage: {expected_damage}\")\n",
    "\n",
    "    logger.debug(\"Difference: \" + str(damage - expected_damage))\n",
    "    logger.debug(\"Different as percentage: \" + '%.2f' %\n",
    "                 ((damage - expected_damage) / expected_damage * 100) + \"%\")\n",
    "\n",
    "# main function\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    skombo()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a8c00dd9af4e1c93e4338362a27a62462f0e60bdb92fa770fcc27a8ee26261a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
